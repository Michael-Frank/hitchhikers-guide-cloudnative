= Qivicon - Best Practices für Docker
:author: Josef Fuchshuber <josef.fuchshuber@qaware.de>
v1.0, 12.09.2016: First final version "qivicon-in-a-box"
include::config.adoc[]

Docker und seine Werkzeugkette decken den kompletten Lebenszyklus von Software-Containern
ab: Build, Ship und Run. In diesem Dokument sind Docker Best Practices als "Dos and Don'ts"
für alle drei Ebenen gesammelt.

== Build

=== Wiederverwendung und Vererbung von Images

Wann immer es möglich ist, sollten Basis-Images für die eigenen Images/Container
verwendet werden (`FROM` statement). Durch die daraus bestehende Vererbungshierarchie
(z.B. Betriebssystem-, Java-, Application-Server- und Application-Image) bleiben
die einzelnen Images möglichst schlank und die einzelnen Schichten können einfach
ausgetauscht (z.B. bei Security Fixes) werden. Zudem fördern die Basis-Images die
Vereinheitlichung aller Images im Projekt oder sogar darüber hinaus (z.B. Basis-Images
für spezielle Betriebsumgebung oder speziellen Sicherheitsanforderungen).

=== Ein Docker-Build muss wiederholbar sein

Wird ein Image aus einem Dockerfile erzeugt, muss sichergestellt werden, dass
ein Build zu einem späteren Zeitpunkt ein identisches Image erzeugt. Damit dies
sichergestellt ist, müssen für alle Abhängigkeiten Versionsnummern verwendet werden.

* Alle Dateien, die vom Image-Build benötigt werden, müssen im SCM-Repository des
Dockerfile liegen.
* Kein `LATEST`-Tag, sondern wenn möglich immer feste Versionen in der `FROM`
Anweisung verwenden.
* Bei der Installation von Software-Paketen immer eine Version definieren.

Während der Entwicklung kann von diesen Punkten abgewichen werden, spätestens bei
einem Release eines Docker Images müssen sie aber eingehalten werden.

```
RUN apt-get update && apt-get install -y ruby1.9.1
```

=== Die Reihenfolge der Befehle im Dockerfile ist wichtig

Beim Docker-Build werden die Befehle im Dockerfile von oben nach unten abgearbeitet.
Jeder erfolgreiche Befehl erzeugt einen Layer im Container-Dateisystem.
Dieser Layer kann beim nächsten Build des eigenen, oder eines anderen Images
wiederverwendet werden. Deshalb ist es sehr wichtig, dass die Befehle am Anfang
eines Dockerfiles sich seltener ändern sollen als die darunterliegenden Befehle.
Wenn man das beachtet, können Folge-Builds eines Images beschleunigt werden, denn
der Build wird erst bei einer Änderung des betroffenen Layers angestoßen.

Das folgende Beispiel zeigt ein Dockerfile mit einem `ADD` Befehl eines Shell-Skripts,
an dem noch gearbeitet wird. Zudem ist ein `yum install` Befehl enthalten. Bei
diesem Beispiel ist es besser, den `ADD` Befehl an das Ende zu stellen:

```
FROM mybase-image
RUN yum -y install mypackage && yum clean all -y
ADD myfile /var/myfile
```

In diesem Fall wird bei jeder Änderung der Datei "myfile" und bei einer Wiederholung
des Builds, für den `yum install` Befehl der Layer aus dem Cache verwendet und nur
ein Layer für den `ADD` Befehl erzeugt.

Beim Umdrehen der Befehle würde folgendes passieren:

```
FROM mybase-image
ADD myfile /var/myfile
RUN yum -y install mypackage && yum clean all -y
```

Jedes Mal, wenn sich die Datei "myfile" ändert und ein Docker-Build angestoßen wird,
invalidiert der `ADD` Befehl schon den Layer-Cache. Deshalb muss auch der
`yum install` Befehl nochmals ausgeführt werden um einen weiteren Layer zu erzeugen.

=== Container mit mehreren Prozessen sollten vermieden werden

Es ist nicht zu empfehlen, dass mehrere Services, wie z.B. eine Datenbank und einen
SSH-Daemon, in einem Container auszuführen. Das ist nicht nötig, denn Container
sind sehr leichtgewichtig und miteinander kommunizierende Prozesse können über
Docker Container-Links einfach zusammengebracht werden. Falls
Kubernetes als Laufzeitumgebung verwendet wird, können zusammengehörende Container
in einem gemeinsamen _POD_ ausgeführt werden.

Diese Art der Zusammenarbeit sorgt dafür, dass die Container für ihre Kommunikation
einen gemeinsamen Netzwerk-Namespace haben. Auch Updates sind weniger problematisch,
da jedes einzelne Image einfacher, unabhängiger und dadurch auch häufiger aktualisiert
werden kann. Das _Signal Handling_ ist mit einem Prozess je Container auch klarer
und einfacher. Denn in diesem Fall müssen die Signale nicht zu jeden einzelnen
Prozess durchgegeben werden.

=== Mehrfachkommandos im `RUN` Kommando verwenden

Wie schon oben erwähnt, erzeugt jeder `RUN` Befehl einen eigenen
Layer des Container-Dateisystems. Je weniger Layer ein Docker Image besitzt,
desto besser funktionieren die Optimierungen beim Bauen und Verteilen der
Docker-Images. Deshalb sollten, immer wenn es möglich ist, mehrere zusammengehörige
Befehle in einem `RUN` Kommando zusammengefasst werden.

Beispiel: Installation von mehreren Software-Paketen mit `apt-get`

```
RUN apt-get update && apt-get install -y wget \
	git-core=1:1.9.1-1 \
	subversion=1.8.8-1ubuntu3.2 \
	ruby=1:1.9.3.4 && \
	apt-get clean
```

Beispiel: Herunterladen, entpacken, installieren und aufräumen der TMP-Dateien
einer Oracle Server JRE Installation

```
RUN wget --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" -O /tmp/server-jre-8u101-linux-x64.tar.gz http://download.oracle.com/otn-pub/java/jdk/8u101-b13/server-jre-8u101-linux-x64.tar.gz && \
	mkdir /opt/java-oracle && \
	tar -zxf /tmp/server-jre-8u101-linux-x64.tar.gz -C /opt/java-oracle/ && \
	rm -rf /tmp/server-jre-8u101-linux-x64.tar.gz
```

=== Temporäre Dateien entfernen

Alle temporären Dateie, die während des Build-Prozesses entstehen, sollten entfernt werden.
Das betrifft auch alle Dateien die mit dem `ADD` Kommando hinzugefügt wurden.

Zum Beispiel sollten nach der Installation eines Linux-Paketes mit YUM immer mit
`yum clean` die temporären Caches aufgeräumt werden. Damit für den YUM Cache kein
unnötiger Image-Layer im Container erzeugt wird, kann immer ein `RUN` Kommando
nach diesm Schema verwendet werden:

```
RUN yum -y install mypackage1 && \
    yum -y install mypackage2 && \
    yum clean all -y
```

_Achtung:_ Was passiert, wenn die Kommandos als mehrzeilig ausgeführt werden?

```
RUN yum -y install mypackage1
RUN yum -y install mypackage2 && yum clean all -y
```

Der erste `yum` Aufruf hinterlässt Dateien in seinem Layer. Diese können später
nicht mehr vom `yum clean` entfernt werden. Diese Dateien sind zwar im finalen
Image nicht sichtbar, sind aber in den darunterliegenden Layern weiterhin vorhanden.

Dieses Schema kann auch bei der Verwendung von `apt-get` verwendet werden:

```
RUN apt-get update && \
    apt-get install -y mypackage1 mypackage2 && \
    apt-get clean
```

Mit der aktuellen Implementierung des Docker Builds ist es nicht möglich, das Filesystem eines
älteren Layers aufzuräumen. Deshalb ist dieser Punkt für die Erstellung von
möglichst schlanken Docker-Images sehr wichtig. Zusätzlich erzeugen Mehrfachkommandos
in einem `RUN` Kommando weniger Layers, was wiederum den Download und das Auspacken
der Images verbessert.

=== Wichtige Ports immer mit `EXPOSE` veröffentlichen

Der `EXPOSE` Befehl macht einen Container-Port für das Host-System oder einen
anderen Container zugreifbar. Container-Ports können zwar auch bei einem `docker run`
Befehl definiert werden, doch macht eine Definition im Dockerfile per `EXPOSE`
für Mensch und Maschine einfacher die nötigen Ports sichtbar zu machen:

* Die Exposed-Ports des Images werden in der Ports-Spalte eines `docker ps`
Befehls angezeigt.
* Alle Exposed-Ports werden in den Image-Metadaten eines `docker inspect`
Befehls aufgeführt.
* Exposed-Ports werden für "linked" Containern automatisch verbunden.

Weitere Informationen über das Port-Handling von Docker ist in der Docker
Dokumentation <<docport>> zu finden.

=== Environment Variablen definieren

Am besten werden Environment Variablen mit dem `ENV` Befehl definiert.

```
ENV JAVA_HOME /opt/java-oracle/jdk1.8.0_92
ENV MAVEN_HOME /usr/share/maven
```

Dieses Vorgehen bringt mehrere Vorteile mit sich:

1. Im Dockerfile sind die definierten Environment Variablen schnell ersichtlich
2. Die definierten Environment Variablen können beim Build und bei der Ausführung
des Containers verwendet werden.
3. Environment Variablen können beim Starten eines Containers einfach überschrieben
werden, z.B. umgebungsabhängige Konfigurationswerte.
4. Environment Variablen machen das Entwicklerleben an vielen Stellen einfacher:
   * Durch eine einheitliche Definition der Anwendungsversionen (z.B. `ENV APP_VERSION=1.2.3`)
   als Environment Variable, können Entwickler während der Laufzeit (z.B. Fehleranalyse)
   auch ohne Zugriff auf ein Dockerfile die Version einer Anwendung überprüfen.
   * Beim Bau von Basis-Images kennt man in den seltensten Fällen die späteren
   Child-Container. Deshalb ist es nicht ratsam fixe Default-Passwörter zu definieren
   und diese auch in den Child-Containern zu verwenden. Es ist besser, wenn man
   Environment Variablen für Passwörter definiert und damit überschreibbar macht:

```
docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:5.7
```

=== Keine SSH-Daemons verwenden

Auf SSH-Daemons in Docker Images zu verzichten ist einfach: In laufende Container
kann lokal direkt per `docker exec` zugriffen werden. Dies funktioniert analog auch
in verteilten Container-Umgebungen wie z.B. Docker Swarm oder Kubernetes (`kubectl exec`)

=== `exec` in Wrapper-Skripten benutzen

Auszug aus <<gfdia>>:

_Many images use wrapper scripts to do some setup before starting a process for
the software being run. It is important that if your image uses such a script,
that script should use exec so that the script’s process is replaced by your
software. If you do not use exec, then signals sent by docker will go to your
wrapper script instead of your software’s process. This is not what you want -
as illustrated by the following example:
Say that you have a wrapper script that starts a process for a server of some
kind. You start your container (using docker run -i), which runs the wrapper
script, which in turn starts your process. Now say that you want to kill your
container with CTRL+C. If your wrapper script used exec to start the server
process, docker will send SIGINT to the server process, and everything will
work as you expect. If you didn’t use exec in your wrapper script, docker will
send SIGINT to the process for the wrapper script - and your process will keep
running like nothing happened._

Wichtig ist, dass ein Prozess in einem Docker Container immer mit PID 1
gestartet wird. Das führt dazu, dass beim Beenden dieses Prozesses der komplette
Container und alle seine Kind-Prozesse des "PID 1 Prozesses" getötet werden.

Mehr Informationen zum "Docker and the PID 1 zombie reaping problem" können in
einem Blog-Artikel <<datp1zrp>> nachgelesen werden. Tiefe technische Informationen
zum Thema "PID 1 und Init Systems" können im Blog Artikel "Demystifying the init
system (PID 1)" <<dtisp1>> nachgelesen werden.

=== Kenne den Unterschied zwischen dem CMD und ENTRYPOINT Befehl

Beide Befehle ähneln sich zwar in ihrer Syntax, bewirken aber unterschiedliche Dinge:
Der `CMD` Befehl definiert das Kommando, das ausgeführt wird, wenn beim Start des
Containers keine weiteren Parameter übergeben werden. Durch die Verwendung des
`ENTRYPOINT` Befehls gleicht die Verwendung eines Images, der eines Prozesses.


* Ist im Dockerfile nur der `CMD` Befehl angegeben, wird das definierte Kommando
nur dann ausgeführt, wenn beim `docker run` keine weiteren Parameter übergeben werden.
* Ist im Dockerfile nur ein `ENTRYPOINT` definiert, werden alle Parameter des
`docker run` Befehls beim Ausführen des Containers an den `ENTRYPOINT` weitergegeben.
Falls keine Parameter übergeben werden, wird der `ENTRYPOINT` ebenfalls ausgeführt.
* Ist im Dockerfile ein `CMD` Befehl und ein `ENTRYPOINT` definiert und werden beim
`docker run` keine Parameter übergeben, werden die im `CMD` Befehl definierten Parameter
an den `ENTRYPOINT` übergeben.

Beispiel:

.Dockerfile
----
FROM ubuntu:trusty
ENTRYPOINT ["/bin/ping","-c","3"]
CMD ["localhost"]
----

.Ausgabe
----
$ docker run ping-image
PING localhost (127.0.0.1) 56(84) bytes of data.
64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=0.015 ms
64 bytes from localhost (127.0.0.1): icmp_seq=2 ttl=64 time=0.027 ms
64 bytes from localhost (127.0.0.1): icmp_seq=3 ttl=64 time=0.032 ms

--- localhost ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 1999ms
rtt min/avg/max/mdev = 0.025/0.038/0.051/0.010 ms
----

CAUTION: Achtung bei der Verwendung von `ENTRYPOINT`: Es erschwert z.B. die Ausführung einer
Shell. Die Praxis zeigt, dass die meisten Docker-Benutzer das Prinzip und die
Unterschiede zwischen  `ENTRYPOINT` und  `CMD` nicht kennen und im Umgang mit
"ENTRYPOINT" Images schnell verwirrt sind: Ihr Standard-Vorgehen um eine Shell zu
öffnen funktioniert nicht mehr:

```
# docker run -i -t ping-image /bin/bash
```

Der `ENTRYPOINT` eines Images kann nur mit dem Parameter-Option "--entrypoint"
des `docker run` Befehls überschrieben werden:

```
# docker run -i --entrypoint /bin/bash -t ping-image
```

=== Verwende Tools zu Qualitätssicherung von Dockerfiles und Images

Ein `Docker-Linter` Werkzeug analysiert ein Dockerfile und zeigt Warnings und Tips
um die Qualität des Dockerfiles und des daraus entstehenden Images zu verbessern.
Die Werkzeuge dazu sind noch relativ neu und befinden sich gerade in Entwicklung.
Hadolint (Haskell Dockerfile Linter <<hadolint>>) ist ein Open Source Projekt, dass
schon jetzt eingesetzt werden kann.

Docker Images können auch Security-Checks unterzogen werden. Diese Werkzeuge
integrieren sich meistens direkt in die CI/CD-Pipeline und sind kommerziell, aber
z.T. kostenlos

* Docker Security Scanning: <<dockerss>>
* FlawCheck: <<flawcheck>>

Docker Laufzeitumgebungen können mit der "Docker Bench for Security" überprüft
werden. Die Docker Bench ist ein Skript, dass Common Best Practices für den
Produktionsbetrieb von Docker Containern überprüft.

== Ship

=== Versionierung von eigenen Images

Die Versionierung (Tagging) von Docker-Images ist wichtig und wird oft vernachlässigt.
Damit Container und Images reproduzierbar erstellt und ausgeführt werden können,
ist eine saubere Versionierung wichtig.

Wird ein Release eines Images erstellt, muss an der Version des Images auch die
Version der darin enthaltenen Anwendung klar erkenntlich sein. Für jedes Release
einer Anwendung, sollte also auch ein Docker-Image mit der Version des Anwendungs-
Releases erstellt und in der Docker Registry veröffentlicht werden. Veröffentlichte
Releases dürfen in der Docker Registry nicht nochmals unter der gleichen Version
(Tag) veröffentlich werden. Denn wenn ein Docker Daemon bereits ein Tag eines
Images im Cache hat, lädt er im Standardverhalten beim Start eines Containers
keine Updates mehr aus der Docker Registry. Nur beim Docker `build` Befehl
kann mit der Option `--pull` immer auf eine neue Version des Basis-Images geprüft werden.

Durch das Tagging von Docker Images sollte auch die Abwärtskompatibilität ausgedrückt
werden. Sobald ein Image durch eine Änderung nicht mehr abwärtskompatibel ist,
z.B. eine zentrale Änderung eines Basis-Images führt dazu, dass ableitende Images
nicht mehr funktionieren würden, muss eine neue Version (Tag) des Basis-Images
erstellt werden. Nur dieses Vorgehen schützt Images vor ungewollten Updates von
Basis-Images.

=== Zentrale Repositories aus Build-Jobs heraus befüllen

In einem zentralen Docker Repository (z.B. Docker Hub) sollte immer erkennbar sein,
wer wann welches Image im Repository abgelegt hat. Am einfachsten lässt sich das
über Build-Jobs auf einen CI-Server (z.B. Jenkins) umsetzen. Auf einem Buil-Server
ist für jeden Build der Trigger, die Revisionsnummer des SCM und das Build-Protokoll
vorhanden.

=== Public Repositories nur als Proxy Repository verwenden

Dieser Punkt trägt auch zur Wiederholbarkeit eines Docker Builds bei. Denn man
muss damit rechnen, dass Images aus Public Repositories irgendwann nicht mehr
verfügbar sind (z.B. ein Public Repository wird komplett abgeschaltet, oder Version
eines Images wurde gelöscht). Das Problem kann durch ein eigenes Proxy
Repository umgangen werden. In diesem Fall werden die verwendeten Public Images
im Proxy gespeichert und man ist von Änderungen im Public Repository geschützt.

=== Ein Image für alle Umgebungen

Es sollte immer das Ziel sein, das Images unabhängig von einer Umgebung sind und
zu einer Version immer nur in Image im der Docker-Registry vorhanden ist. Die
umgebungsabhängigen Konfigurationen kommen erst bei der Ausführung hinzu: z.B.
über Environment Variablen, Konfigurationsdateien die per `volume` eingebunden werden
oder Config-Services wie etcd, Zookeeper oder Spring Cloud Config.

== Run

=== Volumes for Persistent Data

Zur Speicherung von persistenten Daten sollen Docker Images immer `Volumes` verwenden.
Volumes sind im einfachsten Fall ein Teil-Mount des Dateisystems des Docker-Hosts.
Bei komplexeren Laufzeitumgebungen (z.B. Kubernetes, DC/OS) können dies auch
verteilte Dateisysteme oder Netzwerk-Storages sein. In diesem Fall garantiert die
Laufzeitumgebung, dass beim Neustart eines Containers sein persistenter Zustand
auf dem aktuellen Docker-Host des Clusters vorhanden ist und per Docker `Volume`
eingebunden werden kann. Werden persistente Daten an beliebige Orte im Dateisystem
des Containers abgelegt, ist die Wiederherstellung der Daten nicht gesichert.

Darüber hinaus machen es `Volumes` im Dockerfile dem Benutzer viel einfacher, die
Laufzeitumgebung korrekt aufzusetzen: Durch die `Volumes` im Dockerfile ist
schnell ersichtlich, welche `Volumes` und `Mounts` für die Sicherung der
persistenten Daten nötig sind.

=== Logging

Wenn man den Single-Process-Per-Container Ansatz beachtet, sollten die Anwendungs-Logs
immer direkt auf `Standard Out` geschrieben werden. Dadurch ist der Zugriff
standardisiert und die Logs können von einem zentralen Mechanismus einfach eingesammelt
werden. Auch für Entwickler ist es immer von Vorteil, wenn per `docker logs` oder
`kubectl logs` direkt auf die wichtigsten Logs der Anwendung zugegriffen werden
kann.

Falls ein Image die Logs in eine Datei schreibt, müssen immer manuelle Operationen
für den Zugriff implementiert oder konfiguriert werden.

=== Health- und Readiness-Checks

Damit während der Ausführung eines Containers überprüft werden kann, ob die
Anwendung im Container funktioniert (in den seltensten Fällen reicht dazu die
Prüfung, ob ein Prozess läuft, oder ein Netzwerk-Socket geöffnet ist), muss in
Container-Anwendungen ein Health-Check eingebaut werden. Im einfachsten Fall kann
der Health-Check per HTTP-Request aufgerufen werden. Da es sich beim Health-Check
um eine Machine-To-Machine Schnittstelle handelt, ist die einfache Interpretation
des Check-Ergebnisses wichtig. Bei HTTP-Health-Checks bietet sich eine einfache
Rückgabe des Health-Status per HTTP-Code an:

* HTTP-Code `200`: `OK`
* HTTP-Code ungleich `200`: `NOT OK`

Detail-Informationen können zusätzlich im Response-Body, in einem maschinenlesbaren
Format (z.B. JSON), enthalten sein. Readiness-Checks sind eine Sonderform von
Health-Checks. Erst wenn der Readiness-Check `OK` liefert, ist eine Anwendung
im Container komplett hochgefahren und kann benutzt werden (z.B. erst dann darf
die Anwendung von einem Loadbalancer/Proxy angesprochen werden.).

Welche Details in der Umsetzung von Health-Checks beachtet werden müssen, gibt die
Container-Laufzeitumgebung vor.

* Docker: Siehe <<dochealth>>
* Kubernetes: <<kubehealth>>
* DC/OS Marathon: <<dcoshealth>>

=== Fail-Fast Mechanismus nutzen

Unterstützt die Container-Laufzeitumgebung automatische Reboots von Containern,
sollte dieses Feature zur Verbesserung der Resilienz genutzt werden. Die Idee
hinter Fail-Fast ist das schnelle Beenden des Container-Prozesses im Fehlerfall:
z.B. wenn die Anwendung Ressourcen-Probleme (Speicher, Threading) oder
Integrations-Probleme (z.B. Fremdsystem-Anbindung) identifiziert, die durch einen
Neustart der Anwendung behoben werden können.

Dies ist z.B. auch der Fall, wenn eine Anwendung A1 im Container C1 eine
Abhängigkeit zu einer Anwendung A2 in einem Container C2 hat und beide Container
gleichzeitig starten. A1 kann erst auf A2 zugreifen, wenn A2 komplett gestartet ist.
Fail-Fast in diesem Szenario würde für C1 bedeuten, dass er sofort beendet wird,
wenn A1 nicht auf A2 zugreifen kann. Bemerkt die Laufzeitumgebung das
Terminieren von C1, führt diese so lange einen Neustart von C1 durch (z.B.
Docker Restart Policies, Kubernetes Replicas, DC/OS Instances), bis A2 vollständig
gestartet ist und C1 einen erfolgreichen Health-Check ausliefert.

:sectnums!:
== Quellen
[bibliography]
- [[[gfdia]]] Guidance for Docker Image Authors (http://www.projectatomic.io/docs/docker-image-author-guidance/)
- [[[datp1zrp]]] (https://blog.phusion.nl/2015/01/20/docker-and-the-pid-1-zombie-reaping-problem/)
- [[[dtisp1]]](https://felipec.wordpress.com/2013/11/04/init/)
- [[[docport]]](http://docs.docker.io/en/latest/use/port_redirection/)
- [[[dochealth]]](https://docs.docker.com/engine/reference/builder/#/healthcheck)
- [[[kubehealth]]](http://kubernetes.io/docs/user-guide/liveness/)
- [[[dcoshealth]]](https://mesosphere.github.io/marathon/docs/health-checks.html)
- [[[hadolint]]](https://github.com/lukasmartinelli/hadolint)
- [[[dockerss]]](https://docs.docker.com/docker-cloud/builds/image-scan/)
- [[[flawcheck]]](https://www.flawcheck.com/)
